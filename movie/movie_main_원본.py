# -*- coding: utf-8 -*-
"""movie_main_원본.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R8fS76cYhRafSw48jLLOjG-Z5o4BQkel

# 메인 파일 원본
"""

from google.colab import drive
drive.mount('/content/drive')
#드라이브 연결

# !pip install deepctr
# # tensorflow version  == 2.8.0
# # sys version == 3.10.12
# !pip install tensorflow==2.8.0
# !pip install import-ipynb

import numpy as np
import tensorflow as tf
import pandas as pd
import import_ipynb
import os
from deepctr.feature_column import SparseFeat,get_feature_names
from deepctr.models import FLEN, DeepFM
from sklearn.metrics import log_loss, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

if __name__ == "__main__":
    data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/천재교육 프로젝트/1204 딥러닝 기초/movielens.csv')

    sparse_features = ['userId', 'title', 'tag']

    data[sparse_features] = data[sparse_features].fillna('-1', )
    target = ['target']

    # 1.Label Encoding for sparse features,and do simple Transformation for dense features
    for feat in sparse_features:
        lbe = LabelEncoder()
        data[feat] = lbe.fit_transform(data[feat])

    # 2.count #unique features for each sparse field,and record dense feature field name

    field_info = dict(userId='userId', title='title', genres='genres', tag = 'tag', ratings = 'rating')

    fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(), embedding_dim=4)
                          for feat in sparse_features]
    dnn_feature_columns = fixlen_feature_columns
    linear_feature_columns = fixlen_feature_columns

    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)

    # 3.generate input data for model

    train, test = train_test_split(data, test_size=0.2, random_state=2020)
    train_model_input = {name: train[name] for name in feature_names}
    test_model_input = {name: test[name] for name in feature_names}


    # 4.Define Model,train,predict and evaluate
    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')
    model.compile("adam", "binary_crossentropy",
                  metrics=['binary_crossentropy'], )

    history = model.fit(train_model_input, train[target].values,
                        batch_size=256, epochs=10, verbose=2, validation_split=0.2,)
    pred_ans = model.predict(test_model_input, batch_size=256)
    test['pred_target'] = pred_ans
    print("test LogLoss", round(log_loss(test[target].values, pred_ans), 4))
    print("test AUC", round(roc_auc_score(test[target].values, pred_ans), 4))
    result_df = test[['userId', 'title', 'pred_target']]
    # result_df.to_csv('/content/drive/MyDrive/Colab Notebooks/천재교육 프로젝트/1204 딥러닝 기초/final_model_predictions.csv', index=False)

    original_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/천재교육 프로젝트/1204 딥러닝 기초/movielens.csv')
    lbe = LabelEncoder()
    lbe.fit(original_data['title'])
    result_df['title'] = lbe.inverse_transform(result_df['title'])
    result_df.to_csv('/content/drive/MyDrive/Colab Notebooks/천재교육 프로젝트/1204 딥러닝 기초/final_decoding.csv', index=False)
